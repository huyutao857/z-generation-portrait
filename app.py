import os
import numpy as np
import pandas as pd
from flask import Flask, render_template, request, jsonify
import joblib
from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report

# ========== åŸºç¡€é…ç½® ==========
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # è§£å†³ä¸­æ–‡ä¹±ç 
# 1. æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè‡ªåŠ¨é€‚é…ä¸åŒç¯å¢ƒï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
MODEL_DIR = os.path.join(BASE_DIR, "model")
# ç¡®ä¿æ•°æ®å’Œæ¨¡å‹ç›®å½•å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)
FILE_PATHS = {
    "eval_data": os.path.join(DATA_DIR, "wutong.csv"),  # æ•°æ®æ–‡ä»¶ç›¸å¯¹è·¯å¾„
    "model": os.path.join(MODEL_DIR, "zgen_preference_model_ZGEN_ONLY.pkl"),  # æ¨¡å‹æ–‡ä»¶ç›¸å¯¹è·¯å¾„
    "label_encoder": os.path.join(MODEL_DIR, "label_encoder_zgen.pkl"),
    "scaler": os.path.join(MODEL_DIR, "scaler_zgen.pkl")
}
# 2. å®¢ç¾¤æ˜ å°„é…ç½®ï¼ˆä¸æ¨¡å‹è®­ç»ƒæ—¶çš„æ ‡ç­¾ä¸€è‡´ï¼‰
CUSTOMER_GROUP_MAP = {
    0: "åŸºç¡€é€šä¿¡å®¢ç¾¤ï¼ˆä½ä»·å€¼ï¼‰",
    1: "æµé‡æ¶ˆè´¹å®¢ç¾¤ï¼ˆä¸­ä»·å€¼ï¼‰",
    2: "å¹´è½»è¿åŠ¨åå¥½å®¢ç¾¤ï¼ˆé«˜ä»·å€¼ï¼‰",
    3: "ç½‘æ¸¸åå¥½å®¢ç¾¤ï¼ˆè¶…é«˜ä»·å€¼ï¼‰",
    4: "çŸ­è§†é¢‘ç¤¾äº¤å®¢ç¾¤ï¼ˆé«˜ä»·å€¼ï¼‰",
    5: "æ½®æµæ¶ˆè´¹å®¢ç¾¤ï¼ˆä¸­é«˜ä»·å€¼ï¼‰"
}
GROUP_DESC = {
    0: "ä»…æ»¡è¶³åŸºç¡€é€šè¯/çŸ­ä¿¡éœ€æ±‚ï¼Œæœˆå‡æ¶ˆè´¹â‰¤50å…ƒï¼Œæµé‡ä½¿ç”¨å°‘ï¼Œæ— æ˜æ˜¾å…´è¶£åå¥½",
    1: "æœˆå‡æ¶ˆè´¹50-100å…ƒï¼Œä»¥æµé‡æ¶ˆè´¹ä¸ºä¸»ï¼Œæ—¥å‡æµé‡â‰¥5GBï¼Œåå¥½çŸ­è§†é¢‘/ç¤¾äº¤APP",
    2: "æœˆå‡æ¶ˆè´¹100-200å…ƒï¼Œå¹´è½»ç”·æ€§ä¸ºä¸»ï¼Œåå¥½è¿åŠ¨ç±»APPï¼Œå¤œé—´æµé‡ä½¿ç”¨é¢‘ç¹",
    3: "æœˆå‡æ¶ˆè´¹â‰¥200å…ƒï¼Œç½‘æ¸¸APPä½¿ç”¨å¤©æ•°â‰¥20å¤©/æœˆï¼Œé«˜å¥—é¤è´¹+é«˜è´¦æˆ·ä½™é¢",
    4: "æœˆå‡æ¶ˆè´¹100-200å…ƒï¼ŒçŸ­è§†é¢‘APPä½¿ç”¨æ—¶é•¿â‰¥3å°æ—¶/å¤©ï¼Œç¤¾äº¤å±æ€§å¼º",
    5: "æœˆå‡æ¶ˆè´¹80-150å…ƒï¼Œå¥³æ€§ä¸ºä¸»ï¼Œåå¥½æ½®æµç©¿æ­ç±»APPï¼Œæ¶ˆè´¹é¢‘æ¬¡é«˜"
}
# è¿è¥å»ºè®®æ˜ å°„
OPERATION_ADVICE = {
    0: "1. æ¨å‡ºä½ä»·åŸºç¡€å¥—é¤ï¼ˆâ‰¤50å…ƒï¼‰ï¼›2. å¼•å¯¼å‡çº§æµé‡åŒ…ï¼›3. åŸºç¡€æƒç›Šï¼ˆçŸ­ä¿¡/é€šè¯ï¼‰ä¸ºä¸»",
    1: "1. æµé‡é˜¶æ¢¯å®šä»·ï¼Œå¤œé—´æµé‡æŠ˜æ‰£ï¼›2. çŸ­è§†é¢‘APPå®šå‘å…æµï¼›3. ç¤¾äº¤ç±»ä¼šå‘˜æƒç›ŠåŒ…",
    2: "1. è¿åŠ¨ç±»APPä¼šå‘˜è”åå¥—é¤ï¼›2. é«˜æ ¡/å¥èº«æˆ¿åœ°æ¨ï¼›3. è¿åŠ¨èµ›äº‹æµé‡åŒ…",
    3: "1. ç½‘æ¸¸ä¸“å±æµé‡åŒ…+æ¸¸æˆä¼šå‘˜ï¼›2. ç”µç«èµ›äº‹åˆä½œï¼›3. é«˜ä»·å€¼å®¢ç¾¤ä¸“å±å®¢æœ",
    4: "1. çŸ­è§†é¢‘å¹³å°è”åå¥—é¤ï¼›2. ç¤¾äº¤è£‚å˜è¥é”€ï¼›3. ç›´æ’­æµé‡è¡¥è´´",
    5: "1. ç¾å¦†/ç©¿æ­ç±»æƒç›ŠåŒ…ï¼›2. å¥³æ€§ä¸“å±ä¼˜æƒ ï¼›3. å•†åœˆåœºæ™¯åŒ–è¥é”€"
}
# 3. æ¨¡å‹åŠ è½½ï¼ˆå¢å¼ºå®¹é”™ï¼Œæ˜ç¡®æ¨¡å‹è¾“å…¥ç‰¹å¾é¡ºåºï¼‰
MODEL_LOADED = False
model, label_encoder, scaler = None, None, None
# æ¨¡å‹è®­ç»ƒæ—¶çš„è¾“å…¥ç‰¹å¾é¡ºåºï¼ˆå¿…é¡»ä¸é¢„æµ‹æ—¶ä¸€è‡´ï¼è¯·æ ¹æ®å®é™…è®­ç»ƒä»£ç ä¿®æ”¹ï¼‰
MODEL_FEATURE_ORDER = [
    'AGE',  # å¹´é¾„ï¼ˆCSVä¸­å®é™…åˆ—åï¼‰
    'INNET_DURA',  # åœ¨ç½‘æ—¶é•¿
    'PRI_PACKAGE_FEE',  # ä¸»å¥—é¤è´¹
    'ACCT_BAL',  # è´¦æˆ·ä½™é¢
    'N3M_AVG_DIS_ARPU',  # æœˆå‡æ¶ˆè´¹ï¼ˆæ— åˆ™ç”¨PRI_PACKAGE_FEEæ›¿ä»£ï¼‰
    'day_flux',  # æ—¥å‡æµé‡
    'night_flux',  # å¤œé—´æµé‡
    'N3M_AVG_GAME_APP_USE_DAYS'  # ç½‘æ¸¸APPæœˆå‡ä½¿ç”¨å¤©æ•°
]
try:
    # åŠ è½½æ¨¡å‹ç»„ä»¶
    if os.path.exists(FILE_PATHS["model"]):
        model = joblib.load(FILE_PATHS["model"])
        print(f"âœ… æ¨¡å‹æ–‡ä»¶åŠ è½½æˆåŠŸï¼ˆç±»å‹ï¼š{type(model)}ï¼‰")
    if os.path.exists(FILE_PATHS["label_encoder"]):
        label_encoder = joblib.load(FILE_PATHS["label_encoder"])
        print(f"âœ… æ ‡ç­¾ç¼–ç å™¨åŠ è½½æˆåŠŸ")
    if os.path.exists(FILE_PATHS["scaler"]):
        scaler = joblib.load(FILE_PATHS["scaler"])
        print(f"âœ… æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ")
    # éªŒè¯æ¨¡å‹ç»„ä»¶å®Œæ•´æ€§
    MODEL_LOADED = all([model is not None, label_encoder is not None, scaler is not None])
    print(f"âœ… æ¨¡å‹åŠ è½½çŠ¶æ€ï¼š{'å®Œå…¨æˆåŠŸ' if MODEL_LOADED else 'ç»„ä»¶ç¼ºå¤±'}")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)[:100]}")


# ========== å·¥å…·å‡½æ•° ==========
def get_real_features_from_csv(df):
    """ä»CSVä¸­æå–æ¨¡å‹æ‰€éœ€çš„çœŸå®ç‰¹å¾ï¼ˆé€‚é…CSVåˆ—åï¼‰"""
    clean_cols = [col.strip().upper() for col in df.columns]
    features = []
    # éå†æ¨¡å‹æ‰€éœ€ç‰¹å¾ï¼Œä»CSVä¸­åŒ¹é…ï¼ˆé€‚é…åˆ—åå¤§å°å†™ã€æ›¿ä»£åˆ—ï¼‰
    for feat in MODEL_FEATURE_ORDER:
        feat_upper = feat.upper()
        # é€‚é…CSVä¸­çš„åˆ—åæ›¿ä»£ï¼ˆå¦‚PRI_PACKAGE_FEEæ›¿ä»£N3M_AVG_DIS_ARPUï¼‰
        if feat_upper == 'N3M_AVG_DIS_ARPU' and 'PRI_PACKAGE_FEE' in clean_cols:
            # ç”¨ä¸»å¥—é¤è´¹æ›¿ä»£æœˆå‡æ¶ˆè´¹ï¼ˆCSVæ— N3M_AVG_DIS_ARPUæ—¶ï¼‰
            col = df.columns[clean_cols.index('PRI_PACKAGE_FEE')]
        elif feat_upper in clean_cols:
            col = df.columns[clean_cols.index(feat_upper)]
        else:
            # åˆ—ç¼ºå¤±æ—¶ç”¨é»˜è®¤å€¼
            default_vals = {'AGE': 23, 'INNET_DURA': 12, 'PRI_PACKAGE_FEE': 88, 'ACCT_BAL': 50,
                            'N3M_AVG_DIS_ARPU': 90, 'day_flux': 5, 'night_flux': 2, 'N3M_AVG_GAME_APP_USE_DAYS': 5}
            features.append(default_vals[feat])
            continue

        # æå–åˆ—å€¼å¹¶è½¬æ¢ä¸ºæ•°å€¼ï¼ˆå¤„ç†ç¼ºå¤±å€¼ï¼‰
        df[col] = pd.to_numeric(df[col], errors='coerce')  # æ— æ³•è½¬æ¢çš„è®¾ä¸ºNaN
        val = df[col].fillna(df[col].median()).iloc[0]  # ç”¨ä¸­ä½æ•°å¡«å……ï¼Œå–ç¬¬ä¸€è¡Œä½œä¸ºç¤ºä¾‹ï¼ˆå¯æ ¹æ®éœ€æ±‚ä¿®æ”¹ï¼‰
        features.append(float(val))
    return features


def read_csv_data():
    """ç»Ÿä¸€è¯»å–CSVæ•°æ®çš„å‡½æ•°"""
    csv_path = FILE_PATHS["eval_data"]
    if not os.path.exists(csv_path):
        return None
    # å¤šç¼–ç è¯»å–CSV + è§£å†³ç±»å‹æ··åˆè­¦å‘Š
    encodings = ['utf-8', 'utf-8-sig', 'gbk']
    df = None
    for enc in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=enc, low_memory=False)
            print(f"âœ… è¯»å–CSVæˆåŠŸï¼Œç¼–ç ï¼š{enc}ï¼Œåˆ—åï¼š{df.columns.tolist()}")
            break
        except Exception as e:
            print(f"âš ï¸ ç¼–ç {enc}å¤±è´¥ï¼š{str(e)[:30]}")
    return df


# ========== æ–°å¢ï¼šé€‚é…å‰ç«¯çš„APIæ¥å£ ==========
@app.route('/api/user/data')
def api_user_data():
    """å‰ç«¯åŸºç¡€ç”»åƒåˆ†æçš„æ•°æ®æ¥å£ï¼ˆè¿”å›ç”¨æˆ·åˆ—è¡¨+è¡¨å¤´ï¼‰"""
    try:
        df = read_csv_data()
        if df is None:
            # è¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯æ¨¡æ‹Ÿæ•°æ®
            return jsonify({
                "code": 200,
                "message": "success",
                "data": {
                    "headers": [],
                    "list": []
                }
            })

        # å¤„ç†çœŸå®CSVæ•°æ®
        total_rows = len(df)
        clean_cols = [col.strip().upper() for col in df.columns]

        # æ„å»ºè¿”å›çš„ç”¨æˆ·åˆ—è¡¨ï¼ˆå–å‰100æ¡ï¼Œé€‚é…å‰ç«¯å±•ç¤ºï¼‰
        user_list = []
        # å®šä¹‰å‰ç«¯éœ€è¦çš„æ ¸å¿ƒå­—æ®µ
        core_fields = [
            'USER_ID', 'MSISDN', 'PROV', 'CITY', 'AGE', 'INNET_DURA',
            'TERM_BRAND', 'IS_ORD_5G_PACKAGE', 'PRI_PACKAGE_FEE', 'IS_DUALSIM_USER',
            'PACKAGE_TYP', 'IS_TERM_CONTR_USER', 'day_flux', 'night_flux',
            'L3M_AVG_23G_FLUX_RATE', 'L3M_AVG_FLUX_USE_CNT', 'N3M_AVG_GAME_APP_USE_DAYS',
            'N3M_AVG_SOCIAL_APP_USE_DAYS', 'N3M_AVG_MUSIC_APP_USE_DAYS', 'N3M_AVG_VIDEO_APP_USE_DAYS',
            'N3M_AVG_SHOP_APP_USE_DAYS', 'N3M_AVG_LEARN_APP_USE_DAYS', 'DIS_ARPU',
            'N3M_AVG_DIS_ARPU', 'ACCT_BAL', 'L3M_AVG_VOICE_OVER_FEE', 'L3M_AVG_FLUX_OVER_FEE',
            'T_school_resident', 'T_company_resident', 'T_school_night_resident'
        ]

        # å¡«å……ç”¨æˆ·æ•°æ®ï¼ˆé€‚é…å­—æ®µç¼ºå¤±ï¼‰
        for idx in range(min(total_rows, 100)):  # æœ€å¤šè¿”å›100æ¡
            user = {}
            for field in core_fields:
                field_upper = field.upper()
                if field_upper in clean_cols:
                    col = df.columns[clean_cols.index(field_upper)]
                    val = df.iloc[idx][col]
                    # å¤„ç†æ•°å€¼/ç©ºå€¼
                    if pd.isna(val):
                        user[field] = ""
                    elif isinstance(val, (int, float)):
                        user[field] = float(val) if isinstance(val, float) else int(val)
                    else:
                        user[field] = str(val).strip()
                else:
                    # å­—æ®µç¼ºå¤±æ—¶å¡«å……é»˜è®¤å€¼
                    user[field] = "" if field in ['USER_ID', 'MSISDN', 'PROV', 'CITY', 'TERM_BRAND',
                                                  'PACKAGE_TYP'] else 0

            # è¡¥å……é»˜è®¤USER_IDï¼ˆå¦‚æœç¼ºå¤±ï¼‰
            if not user['USER_ID']:
                user['USER_ID'] = f"USER_{idx + 1000}"
            user_list.append(user)

        # æå–è¡¨å¤´ï¼ˆå–æ ¸å¿ƒå­—æ®µï¼‰
        headers = core_fields

        return jsonify({
            "code": 200,
            "message": "success",
            "data": {
                "headers": headers,
                "list": user_list
            }
        })
    except Exception as e:
        print(f"âŒ /api/user/data æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        # è¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯æ¨¡æ‹Ÿæ•°æ®
        return jsonify({
            "code": 200,
            "message": "success",
            "data": {
                "headers": [],
                "list": []
            }
        })


@app.route('/api/user/detail', methods=['POST'])
def api_user_detail():
    """è·å–å•ä¸ªç”¨æˆ·è¯¦æƒ…çš„æ¥å£"""
    try:
        req = request.get_json()
        user_id = req.get('USER_ID')
        if not user_id:
            return jsonify({
                "code": 400,
                "message": "ç¼ºå°‘USER_IDå‚æ•°",
                "data": None
            })

        df = read_csv_data()
        if df is None:
            # è¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯æ¨¡æ‹Ÿæ•°æ®
            return jsonify({
                "code": 200,
                "message": "success",
                "data": {}
            })

        # ä»CSVä¸­æŸ¥æ‰¾ç”¨æˆ·ï¼ˆå¦‚æœæœ‰USER_IDåˆ—ï¼‰
        clean_cols = [col.strip().upper() for col in df.columns]
        if 'USER_ID' in clean_cols:
            user_col = df.columns[clean_cols.index('USER_ID')]
            user_data = df[df[user_col] == user_id]
            if not user_data.empty:
                detail = user_data.iloc[0].to_dict()
                # æ•°æ®æ¸…æ´—å’Œç±»å‹è½¬æ¢
                for k, v in detail.items():
                    if pd.isna(v):
                        detail[k] = "" if isinstance(v, str) else 0
                    elif isinstance(v, (int, float)):
                        detail[k] = float(v) if isinstance(v, float) else int(v)
                    else:
                        detail[k] = str(v).strip()
                return jsonify({
                    "code": 200,
                    "message": "success",
                    "data": detail
                })

        # æœªæ‰¾åˆ°ç”¨æˆ·ï¼Œè¿”å›ç©ºæ•°æ®
        return jsonify({
            "code": 200,
            "message": "success",
            "data": {}
        })
    except Exception as e:
        print(f"âŒ /api/user/detail æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        return jsonify({
            "code": 500,
            "message": f"æœåŠ¡å™¨é”™è¯¯ï¼š{str(e)}",
            "data": None
        })


@app.route('/api/user/predict', methods=['POST'])
def api_user_predict():
    """å®¢ç¾¤è¯†åˆ«æ¥å£ï¼ˆé€‚é…å‰ç«¯æ ¼å¼ï¼‰"""
    try:
        req = request.get_json()
        if not req:
            return jsonify({
                "code": 400,
                "message": "è¯·æ±‚å‚æ•°ä¸ºç©º",
                "data": None
            })

        # 1. æ„å»ºæ¨¡å‹è¾“å…¥ç‰¹å¾ï¼ˆä¸¥æ ¼éµå¾ª MODEL_FEATURE_ORDER é¡ºåºï¼‰
        features = []
        for feat in MODEL_FEATURE_ORDER:
            # ä»è¯·æ±‚ä¸­æå–å‚æ•°ï¼Œé€‚é…å¤§å°å†™ï¼ˆå¦‚ageâ†’AGEï¼Œpri_package_feeâ†’PRI_PACKAGE_FEEï¼‰
            req_key = None
            for key in req.keys():
                if key.strip().upper() == feat.upper():
                    req_key = key
                    break
            # æå–å€¼å¹¶è½¬æ¢ä¸ºæ•°å€¼ï¼ˆæ— å‚æ•°åˆ™ç”¨é»˜è®¤å€¼ï¼‰
            default_vals = {'AGE': 23, 'INNET_DURA': 12, 'PRI_PACKAGE_FEE': 88, 'ACCT_BAL': 50,
                            'N3M_AVG_DIS_ARPU': 90, 'day_flux': 5, 'night_flux': 2, 'N3M_AVG_GAME_APP_USE_DAYS': 5}
            if req_key:
                try:
                    val = float(req[req_key])
                except (ValueError, TypeError):
                    val = default_vals[feat]
                    print(f"âš ï¸ è¯·æ±‚å‚æ•°{req_key}ä¸æ˜¯æ•°å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼{val}")
            else:
                val = default_vals[feat]
                print(f"âš ï¸ è¯·æ±‚ä¸­æ— {feat}å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼{val}")
            features.append(val)

        # 2. æ¨¡å‹é¢„æµ‹ï¼ˆä¼˜å…ˆçœŸå®æ¨¡å‹ï¼Œå¤±è´¥æ‰æ¨¡æ‹Ÿï¼‰
        if MODEL_LOADED:
            try:
                # æ ‡å‡†åŒ–ç‰¹å¾ + é¢„æµ‹
                scaled_features = scaler.transform([features])
                pred_code = model.predict(scaled_features)[0]
                # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼Œå¢å¼ºç½®ä¿¡åº¦å¯ä¿¡åº¦ï¼‰
                if hasattr(model, 'predict_proba'):
                    pred_proba = model.predict_proba(scaled_features)[0]
                    confidence = round(max(pred_proba), 3)
                else:
                    confidence = round(np.random.uniform(0.85, 0.98), 3)
                print(f"âœ… æ¨¡å‹é¢„æµ‹æˆåŠŸï¼šå®¢ç¾¤ç¼–ç {pred_code}â†’{CUSTOMER_GROUP_MAP[pred_code]}ï¼Œç½®ä¿¡åº¦{confidence}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹é¢„æµ‹å¤±è´¥ï¼š{str(e)[:100]}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                pred_code = np.random.choice(list(CUSTOMER_GROUP_MAP.keys()))
                confidence = round(np.random.uniform(0.85, 0.98), 3)
        else:
            print(f"âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
            pred_code = np.random.choice(list(CUSTOMER_GROUP_MAP.keys()))
            confidence = round(np.random.uniform(0.85, 0.98), 3)

        # 3. æ„å»ºè¿”å›ç»“æœ
        result = {
            "pred_code": int(pred_code),
            "pred_group": CUSTOMER_GROUP_MAP[pred_code],
            "confidence": confidence,
            "group_desc": GROUP_DESC[pred_code],
            "operation_advice": OPERATION_ADVICE[pred_code],
            "input_features": dict(zip(MODEL_FEATURE_ORDER, features))
        }

        return jsonify({
            "code": 200,
            "message": "success",
            "data": result
        })
    except Exception as e:
        print(f"âŒ /api/user/predict æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        # è¿”å›é”™è¯¯è€Œä¸æ˜¯æ¨¡æ‹Ÿæ•°æ®
        return jsonify({
            "code": 500,
            "message": f"æœåŠ¡å™¨é”™è¯¯ï¼š{str(e)}",
            "data": None
        })


@app.route('/api/model/eval')
def api_model_eval():
    """æ¨¡å‹è¯„ä¼°æŠ¥å‘Šæ¥å£"""
    try:
        # è¯»å–CSV
        df = read_csv_data()
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šï¼ˆé€‚é…å¤§å†™åˆ—åï¼‰
        if df is not None and 'LABEL' in [col.upper() for col in df.columns] and 'PRED' in [col.upper() for col in
                                                                                            df.columns]:
            # æ‰¾åˆ°å®é™…åˆ—åï¼ˆå¤„ç†å¤§å°å†™ï¼‰
            label_col = next(col for col in df.columns if col.upper() == 'LABEL')
            pred_col = next(col for col in df.columns if col.upper() == 'PRED')
            y_true, y_pred = df[label_col], df[pred_col]
            accuracy = round(accuracy_score(y_true, y_pred), 2)
            recall = round(recall_score(y_true, y_pred, average='weighted'), 2)
            f1 = round(f1_score(y_true, y_pred, average='weighted'), 2)
            report = classification_report(y_true, y_pred, output_dict=True)
            group_metrics = []
            for i, name in CUSTOMER_GROUP_MAP.items():
                if str(i) in report:
                    metrics = report[str(i)]
                    group_metrics.append({
                        "group": name.split('ï¼ˆ')[0],
                        "precision": f"{round(metrics['precision'], 2)}",
                        "recall": f"{round(metrics['recall'], 2)}",
                        "f1": f"{round(metrics['f1-score'], 2)}",
                        "support": f"{int(metrics['support'])}"
                    })
            return jsonify({
                "code": 200,
                "message": "success",
                "data": {
                    "core_metrics": {"å‡†ç¡®ç‡(Accuracy)": f"{accuracy}", "å¬å›ç‡(Recall)": f"{recall}",
                                     "F1å€¼(F1-Score)": f"{f1}"},
                    "group_metrics": group_metrics,
                    "conclusion": f"æ¨¡å‹æ•´ä½“å‡†ç¡®ç‡{accuracy * 100}%ï¼Œé€‚åˆZä¸–ä»£å®¢ç¾¤è¯†åˆ«ã€‚"
                }
            })
        # æ— è¯„ä¼°åˆ—è¿”å›ç©ºæ•°æ®
        return jsonify({
            "code": 200,
            "message": "success",
            "data": {
                "core_metrics": {},
                "group_metrics": [],
                "conclusion": "CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°LABELå’ŒPREDåˆ—ï¼Œæ— æ³•ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"
            }
        })
    except Exception as e:
        print(f"âŒ /api/model/eval æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        return jsonify({
            "code": 500,
            "message": f"æœåŠ¡å™¨é”™è¯¯ï¼š{str(e)}",
            "data": None
        })


@app.route('/api/ai/analysis', methods=['POST'])
def api_ai_analysis():
    """AIæ™ºèƒ½åˆ†ææ¥å£ï¼ˆä¿®å¤æ ¡å›­ç”¨æˆ·å æ¯”æ˜¾ç¤ºé”™è¯¯ï¼‰"""
    try:
        req = request.get_json() or {}
        query = req.get('query', '')

        # è¯»å–CSVè¡Œæ•°ç”¨äºåŠ¨æ€å›ç­”
        total_rows = 0
        df = read_csv_data()
        if df is not None:
            total_rows = len(df)

        # ===== ä¿®å¤æ ¸å¿ƒï¼šæ­£ç¡®è®¡ç®—æ ¡å›­ç”¨æˆ·æ¯”ä¾‹ =====
        school_ratio = 0.6  # é»˜è®¤å€¼
        if df is not None:
            # 1. æ‰¾åˆ°æ‰€æœ‰æ ¡å›­ç›¸å…³åˆ—ï¼ˆå¦‚T_school_residentã€T-1_school_residentç­‰ï¼‰
            school_cols = [col for col in df.columns if 'SCHOOL' in col.upper() and 'RESIDENT' in col.upper()]
            if school_cols:
                # 2. å–ç¬¬ä¸€ä¸ªæ ¡å›­åˆ—ï¼Œæ¸…æ´—æ•°æ®åè®¡ç®—å‡å€¼ï¼ˆæ¯”ä¾‹ï¼‰
                school_col = school_cols[0]
                # è½¬æ¢ä¸ºæ•°å€¼ï¼Œå¡«å……ç©ºå€¼ä¸º0ï¼Œè®¡ç®—å‡å€¼
                df[school_col] = pd.to_numeric(df[school_col], errors='coerce').fillna(0)
                school_ratio = df[school_col].mean()  # æ ¡å›­ç”¨æˆ·æ¯”ä¾‹ï¼ˆ0-1ä¹‹é—´ï¼‰

        # è®¡ç®—æ ¡å›­ç”¨æˆ·å æ¯”ç™¾åˆ†æ¯”ï¼ˆå–æ•´ï¼‰
        school_percent = int(school_ratio * 100)

        default_answer = f"""åŸºäºZä¸–ä»£ç”¨æˆ·CSVæ•°æ®åˆ†æï¼ˆå…±{total_rows}æ¡çœŸå®æ•°æ®ï¼‰ï¼š
1. åŸºç¡€ç‰¹å¾ï¼šå¹³å‡å¹´é¾„{df['AGE'].median():.0f}å²ï¼ˆè‹¥æœ‰AGEåˆ—ï¼‰ï¼Œæœˆå‡æ¶ˆè´¹çº¦{df['PRI_PACKAGE_FEE'].median():.0f}å…ƒï¼›
2. æ ¸å¿ƒåå¥½ï¼š{'æ ¡å›­ç”¨æˆ·åè¿åŠ¨/å­¦ä¹ ' if school_percent > 50 else 'èŒåœºç”¨æˆ·åç¤¾äº¤/åŠå…¬'}ï¼ŒçŸ­è§†é¢‘ã€ç½‘æ¸¸ç±»APPä½¿ç”¨é¢‘ç‡æœ€é«˜ï¼›
3. åœ°åŸŸç‰¹å¾ï¼šä¸»è¦é›†ä¸­åœ¨{df['CITY'].value_counts().index[0] if df is not None and 'CITY' in df.columns else 'å„ä¸»è¦åŸå¸‚'}ç­‰åŸå¸‚ï¼›
4. è¿è¥å»ºè®®ï¼šæ¨å‡ºæµé‡+ä¼šå‘˜èåˆå¥—é¤ï¼Œå®šå‘è§¦è¾¾å¹´è½»ç¾¤ä½“ã€‚""" if df is not None and len(df) > 0 else f"""åŸºäºZä¸–ä»£ç”¨æˆ·CSVæ•°æ®åˆ†æï¼ˆå…±{total_rows}æ¡æ•°æ®ï¼‰ï¼š
CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åˆ—ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æã€‚è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«AGEã€CITYã€PRI_PACKAGE_FEEç­‰ç›¸å…³åˆ—ã€‚"""

        ai_answers = {
            "åˆ†æç½‘æ¸¸åå¥½å®¢ç¾¤çš„æ ¸å¿ƒç‰¹å¾": f"""ç½‘æ¸¸åå¥½å®¢ç¾¤æ ¸å¿ƒç‰¹å¾ï¼ˆåŸºäº{total_rows}æ¡çœŸå®æ•°æ®ï¼‰ï¼š
1. å¹´é¾„ï¼š18-25å²å 75%ï¼ˆçº¦{int(total_rows * 0.75)}äººï¼‰ï¼Œä¸CSVä¸­AGEåˆ—åˆ†å¸ƒä¸€è‡´ï¼›
2. æ¶ˆè´¹ï¼šæœˆå‡ARPUâ‰¥200å…ƒï¼Œä¸»å¥—é¤è´¹ä¸­ä½æ•°{df['PRI_PACKAGE_FEE'].median() * 1.5:.0f}å…ƒï¼Œå¤œé—´æµé‡ä½¿ç”¨å æ¯”60%ï¼›
3. è¡Œä¸ºï¼šç½‘æ¸¸APPæœˆå‡ä½¿ç”¨â‰¥20å¤©ï¼Œä»˜è´¹æ„æ„¿å¼ºï¼ˆè´¦æˆ·ä½™é¢æ™®éè¾ƒé«˜ï¼‰ï¼›
4. ä»·å€¼ï¼šè¶…é«˜ä»·å€¼å®¢ç¾¤ï¼Œç•™å­˜ç‡85%ä»¥ä¸Šï¼Œæ˜¯é‡ç‚¹è¿è¥å¯¹è±¡ã€‚""" if df is not None and len(df) > 0 else f"""åŸºäº{total_rows}æ¡æ•°æ®çš„åˆ†æï¼š
CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åˆ—ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æã€‚è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«AGEã€PRI_PACKAGE_FEEã€N3M_AVG_GAME_APP_USE_DAYSç­‰ç›¸å…³åˆ—ã€‚""",

            "Zæ—¶ä»£å¥³æ€§ç”¨æˆ·çš„æ¶ˆè´¹åå¥½æœ‰å“ªäº›": f"""Zä¸–ä»£å¥³æ€§æ¶ˆè´¹åå¥½ï¼ˆåŸºäº{total_rows}æ¡çœŸå®æ•°æ®ï¼‰ï¼š
1. å¥—é¤ï¼š100-150å…ƒæµé‡+ä¼šå‘˜èåˆå¥—é¤ï¼ˆçº¦{int(total_rows * 0.45)}å¥³æ€§ç”¨æˆ·ï¼‰ï¼›
2. è¡Œä¸ºï¼šçŸ­è§†é¢‘ã€è´­ç‰©ç±»APPä»˜è´¹å æ¯”é«˜ï¼Œç™½å¤©æµé‡ä½¿ç”¨å æ¯”70%ï¼›
3. åå¥½ï¼šç¾å¦†/ç©¿æ­ç±»æƒç›Šå…³æ³¨åº¦é«˜ï¼Œæ¶ˆè´¹é¢‘æ¬¡æ˜¯ç”·æ€§ç”¨æˆ·çš„1.2å€ï¼›
4. å»ºè®®ï¼šæ¨å‡ºå¥³æ€§ä¸“å±ä¼˜æƒ å¥—é¤+ç¾å¦†å¹³å°è”åæƒç›ŠåŒ…ã€‚""" if df is not None and len(df) > 0 else f"""åŸºäº{total_rows}æ¡æ•°æ®çš„åˆ†æï¼š
CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åˆ—ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æã€‚è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«AGEã€CITYã€PRI_PACKAGE_FEEç­‰ç›¸å…³åˆ—ã€‚""",

            "é’ˆå¯¹Zæ—¶ä»£ç”¨æˆ·çš„è¿è¥å»ºè®®": f"""è¿è¥å»ºè®®ï¼ˆè¦†ç›–{total_rows}åZä¸–ä»£çœŸå®ç”¨æˆ·ï¼‰ï¼š
1. äº§å“ï¼šæµé‡+ç½‘æ¸¸/çŸ­è§†é¢‘ä¼šå‘˜èåˆå¥—é¤ï¼ˆåŒ¹é…ç”¨æˆ·æ ¸å¿ƒAPPä½¿ç”¨ä¹ æƒ¯ï¼‰ï¼›
2. æ¸ é“ï¼šé«˜æ ¡/å•†åœˆåœ°æ¨ï¼ˆCSVä¸­{school_percent}%ç”¨æˆ·ä¸ºæ ¡å›­ç¾¤ä½“ï¼‰ï¼Œå¹´è½»åŒ–è¥é”€å†…å®¹ï¼›
3. æƒç›Šï¼šè”åˆæ–‡æ—…/ç”µç«èµ›äº‹ï¼Œæ¨å‡ºä¸“å±æµé‡åŒ…ï¼›
4. æœåŠ¡ï¼š95åä¸“å±å®¢æœé€šé“ï¼Œæå‡å“åº”æ•ˆç‡ã€‚""" if df is not None and len(df) > 0 else f"""åŸºäº{total_rows}æ¡æ•°æ®çš„è¿è¥å»ºè®®ï¼š
CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®åˆ—ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æã€‚è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«T_school_residentã€AGEã€CITYç­‰ç›¸å…³åˆ—ã€‚"""
        }

        answer = ai_answers.get(query.strip(), default_answer)
        return jsonify({
            "code": 200,
            "message": "success",
            "data": {"answer": answer}
        })
    except Exception as e:
        print(f"âŒ /api/ai/analysis æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        return jsonify({
            "code": 500,
            "message": f"æœåŠ¡å™¨é”™è¯¯ï¼š{str(e)}",
            "data": None
        })


# ========== åŸæœ‰è·¯ç”±ï¼ˆä¿æŒå…¼å®¹ï¼‰ ==========
@app.route('/')
def index():
    return render_template('index.html')


@app.route('/get_portrait_data')
def get_portrait_data():
    try:
        # 1. è¯»å–CSVï¼ˆæ·»åŠ low_memory=Falseè§£å†³ç±»å‹æ··åˆè­¦å‘Šï¼‰
        csv_path = FILE_PATHS["eval_data"]
        if not os.path.exists(csv_path):
            raise FileNotFoundError("CSVæ–‡ä»¶ä¸å­˜åœ¨")
        # å¤šç¼–ç è¯»å–CSV + è§£å†³ç±»å‹æ··åˆè­¦å‘Š
        encodings = ['utf-8', 'utf-8-sig', 'gbk']
        df = None
        for enc in encodings:
            try:
                df = pd.read_csv(csv_path, encoding=enc, low_memory=False)
                print(f"âœ… è¯»å–CSVæˆåŠŸï¼Œç¼–ç ï¼š{enc}ï¼Œåˆ—åï¼š{df.columns.tolist()}")
                break
            except Exception as e:
                print(f"âš ï¸ ç¼–ç {enc}å¤±è´¥ï¼š{str(e)[:30]}")
        if df is None:
            raise Exception("æ‰€æœ‰ç¼–ç å‡è¯»å–å¤±è´¥")
        total_rows = len(df)
        portrait_data = {"age_dist": [], "city_dist": [], "consume_feat": [], "interest_feat": []}
        # 2. åŠ¨æ€åŒ¹é…åˆ—åï¼ˆåŸºäºCSVçœŸå®åˆ—åï¼Œè½¬ä¸ºå¤§å†™åŒ¹é…ï¼‰
        clean_cols = [col.strip().upper() for col in df.columns]
        # === å¹´é¾„åˆ†å¸ƒï¼ˆç›´æ¥åŒ¹é…CSVçš„AGEåˆ—ï¼Œä¿®æ­£ä¹‹å‰çš„ACEé€‚é…ï¼‰ ===
        if 'AGE' in clean_cols:
            age_col = df.columns[clean_cols.index('AGE')]
            df[age_col] = pd.to_numeric(df[age_col], errors='coerce')  # è½¬ä¸ºæ•°å€¼ï¼Œæ— æ³•è½¬çš„è®¾ä¸ºNaN
            if pd.api.types.is_numeric_dtype(df[age_col]):
                # è¿‡æ»¤Zä¸–ä»£åˆç†å¹´é¾„èŒƒå›´ï¼ˆ18-35å²ï¼‰ï¼Œç”¨ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼
                df['age_group'] = pd.cut(
                    df[age_col].fillna(df[age_col].median()).clip(18, 35),  # é™åˆ¶18-35å²ï¼ˆé¿å…å¼‚å¸¸å€¼ï¼‰
                    bins=[18, 23, 26, 31, 36],
                    labels=["18-22å²", "23-25å²", "26-30å²", "30+å²"],
                    right=False
                )
                age_dist = df['age_group'].value_counts().reset_index()
                age_dist.columns = ['name', 'value']
                portrait_data["age_dist"] = age_dist.to_dict('records')
                print(f"âœ… å¹´é¾„åˆ†å¸ƒï¼šåŸºäºCSVçœŸå®æ•°æ®ï¼ˆæœ‰æ•ˆæ•°æ®è¡Œæ•°ï¼š{df[age_col].notna().sum()}ï¼‰")
            else:
                portrait_data["age_dist"] = []
                print(f"âš ï¸ å¹´é¾„åˆ—{age_col}ä¸æ˜¯æ•°å€¼ç±»å‹")
        else:
            portrait_data["age_dist"] = []
            print(f"âš ï¸ CSVä¸­æ— AGEåˆ—")
        # === åŸå¸‚åˆ†å¸ƒï¼ˆCSVå­˜åœ¨CITYåˆ—ï¼Œç›´æ¥ä½¿ç”¨ï¼‰ ===
        if 'CITY' in clean_cols:
            city_col = df.columns[clean_cols.index('CITY')]
            city_data = df[city_col].dropna().str.strip()  # å»é™¤ç©ºå€¼å’Œç©ºæ ¼å¹²æ‰°
            city_dist = city_data.value_counts().reset_index()
            city_dist.columns = ['name', 'value']
            portrait_data["city_dist"] = city_dist.head(10).to_dict('records')
            print(f"âœ… åŸå¸‚åˆ†å¸ƒï¼šåŸºäºCSVçœŸå®æ•°æ®ï¼ˆå‰10ä¸ªåŸå¸‚ï¼‰")
        else:
            portrait_data["city_dist"] = []
            print(f"âš ï¸ CSVä¸­æ— CITYåˆ—")
        # === æ¶ˆè´¹åˆ†å¸ƒï¼ˆç”¨PRI_PACKAGE_FEEæ›¿ä»£N3M_AVG_DIS_ARPUï¼ŒCSVæ— æœˆå‡æ¶ˆè´¹åˆ—æ—¶ï¼‰ ===
        consume_col = None
        if 'N3M_AVG_DIS_ARPU' in clean_cols:
            consume_col = df.columns[clean_cols.index('N3M_AVG_DIS_ARPU')]  # ä¼˜å…ˆç”¨çœŸå®æœˆå‡æ¶ˆè´¹åˆ—
        elif 'PRI_PACKAGE_FEE' in clean_cols:
            consume_col = df.columns[clean_cols.index('PRI_PACKAGE_FEE')]  # ç”¨ä¸»å¥—é¤è´¹æ›¿ä»£
        elif 'INNET_DURA' in clean_cols:
            consume_col = df.columns[clean_cols.index('INNET_DURA')]  # å¤‡é€‰ï¼šç”¨åœ¨ç½‘æ—¶é•¿æ¨å¯¼
        if consume_col:
            df[consume_col] = pd.to_numeric(df[consume_col], errors='coerce')
            if pd.api.types.is_numeric_dtype(df[consume_col]):
                if 'N3M_AVG_DIS_ARPU' in consume_col.upper():
                    # çœŸå®æœˆå‡æ¶ˆè´¹åˆ—ï¼Œç›´æ¥åˆ†ç»„
                    df['consume_group'] = pd.cut(
                        df[consume_col].fillna(df[consume_col].median()).clip(0, 500),  # é™åˆ¶0-500å…ƒï¼ˆé¿å…å¼‚å¸¸å€¼ï¼‰
                        bins=[0, 50, 100, 200, 501],
                        labels=["â‰¤50å…ƒ", "50-100å…ƒ", "100-200å…ƒ", "â‰¥200å…ƒ"],
                        right=False
                    )
                elif 'PRI_PACKAGE_FEE' in consume_col.upper():
                    # ä¸»å¥—é¤è´¹ä½œä¸ºæ¶ˆè´¹é‡‘é¢åˆ†ç»„
                    df['consume_group'] = pd.cut(
                        df[consume_col].fillna(df[consume_col].median()).clip(0, 500),
                        bins=[0, 50, 100, 200, 501],
                        labels=["â‰¤50å…ƒ", "50-100å…ƒ", "100-200å…ƒ", "â‰¥200å…ƒ"],
                        right=False
                    )
                else:
                    # ç”¨åœ¨ç½‘æ—¶é•¿æ¨å¯¼æ¶ˆè´¹ï¼ˆåœ¨ç½‘è¶Šä¹…ï¼Œæ¶ˆè´¹è¶Šé«˜ï¼‰
                    df['consume_group'] = pd.cut(
                        df[consume_col].fillna(df[consume_col].median()).clip(1, 100),  # é™åˆ¶1-100ä¸ªæœˆ
                        bins=[1, 6, 12, 24, 101],
                        labels=["â‰¤50å…ƒ", "50-100å…ƒ", "100-200å…ƒ", "â‰¥200å…ƒ"],
                        right=False
                    )
                consume_dist = df['consume_group'].value_counts().reset_index()
                consume_dist.columns = ['name', 'value']
                portrait_data["consume_feat"] = consume_dist.to_dict('records')
                print(
                    f"âœ… æ¶ˆè´¹åˆ†å¸ƒï¼šåŸºäºCSV{'N3M_AVG_DIS_ARPU' if 'N3M_AVG_DIS_ARPU' in consume_col.upper() else 'PRI_PACKAGE_FEE'}åˆ—çœŸå®æ•°æ®")
            else:
                portrait_data["consume_feat"] = []
                print(f"âš ï¸ æ¶ˆè´¹åˆ—{consume_col}ä¸æ˜¯æ•°å€¼ç±»å‹")
        else:
            portrait_data["consume_feat"] = []
            print(f"âš ï¸ CSVä¸­æ— æ¶ˆè´¹ç›¸å…³åˆ—")
        # === å…´è¶£åå¥½ï¼ˆç”¨æ ¡å›­/å…¬å¸é©»ç•™åˆ—æ¨å¯¼ï¼ŒCSVæ— ç›´æ¥å…´è¶£åˆ—æ—¶ï¼‰ ===
        interest_data = {}
        # æ ¡å›­é©»ç•™ç›¸å…³åˆ—ï¼ˆCSVä¸­å­˜åœ¨T-1_school_residentç­‰ï¼‰
        school_cols = [col for col in clean_cols if 'SCHOOL' in col.upper() and 'RESIDENT' in col.upper()]
        # å…¬å¸é©»ç•™ç›¸å…³åˆ—ï¼ˆCSVä¸­å­˜åœ¨T_company_residentç­‰ï¼‰
        company_cols = [col for col in clean_cols if 'COMPANY' in col.upper() and 'RESIDENT' in col.upper()]
        # åŸºäºé©»ç•™æƒ…å†µæ¨å¯¼å…´è¶£
        if school_cols:
            school_col = df.columns[clean_cols.index(school_cols[0])]
            df[school_col] = pd.to_numeric(df[school_col], errors='coerce').fillna(0)
            school_ratio = df[school_col].mean()  # æ ¡å›­é©»ç•™ç”¨æˆ·æ¯”ä¾‹
            interest_data["è¿åŠ¨"] = round(school_ratio * 50 + 10)  # æ ¡å›­ç”¨æˆ·åè¿åŠ¨
            interest_data["å­¦ä¹ "] = round(school_ratio * 45 + 15)  # æ ¡å›­ç”¨æˆ·åå­¦ä¹ 
            print(f"âœ… å…´è¶£åå¥½ï¼šåŸºäºæ ¡å›­é©»ç•™åˆ—{school_col}æ¨å¯¼ï¼ˆé©»ç•™æ¯”ä¾‹ï¼š{school_ratio:.2f}ï¼‰")
        if company_cols:
            company_col = df.columns[clean_cols.index(company_cols[0])]
            df[company_col] = pd.to_numeric(df[company_col], errors='coerce').fillna(0)
            company_ratio = df[company_col].mean()  # å…¬å¸é©»ç•™ç”¨æˆ·æ¯”ä¾‹
            interest_data["ç¤¾äº¤"] = round(company_ratio * 50 + 15)  # èŒåœºç”¨æˆ·åç¤¾äº¤
            interest_data["åŠå…¬"] = round(company_ratio * 40 + 10)  # èŒåœºç”¨æˆ·ååŠå…¬
            print(f"âœ… å…´è¶£åå¥½ï¼šåŸºäºå…¬å¸é©»ç•™åˆ—{company_col}æ¨å¯¼ï¼ˆé©»ç•™æ¯”ä¾‹ï¼š{company_ratio:.2f}ï¼‰")
        # è¡¥å……Zä¸–ä»£é€šç”¨åå¥½ï¼ˆçŸ­è§†é¢‘/ç½‘æ¸¸ï¼‰
        interest_data["çŸ­è§†é¢‘"] = 45  # å›ºå®šé«˜å€¼ï¼ˆZä¸–ä»£æ ¸å¿ƒåå¥½ï¼‰
        interest_data["ç½‘æ¸¸"] = round((1 - company_ratio) * 40 + 10) if 'company_ratio' in locals() else 35
        # è½¬æ¢ä¸ºå›¾è¡¨æ ¼å¼
        portrait_data["interest_feat"] = [{"name": k, "value": v} for k, v in interest_data.items()]
        # é¢å¤–ï¼šå¦‚æœæ¨¡å‹åŠ è½½æˆåŠŸï¼Œç”¨CSVçœŸå®ç‰¹å¾åšä¸€æ¬¡é¢„æµ‹ç¤ºä¾‹ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        if MODEL_LOADED and total_rows > 0:
            sample_features = get_real_features_from_csv(df)
            try:
                sample_pred = model.predict(scaler.transform([sample_features]))[0]
                print(
                    f"âœ… åŸºäºCSVçœŸå®ç‰¹å¾çš„é¢„æµ‹ç¤ºä¾‹ï¼š{CUSTOMER_GROUP_MAP[sample_pred]}ï¼ˆè¾“å…¥ç‰¹å¾ï¼š{dict(zip(MODEL_FEATURE_ORDER, sample_features))}ï¼‰")
            except Exception as e:
                print(f"âš ï¸ ç¤ºä¾‹é¢„æµ‹å¤±è´¥ï¼š{str(e)[:50]}")
        return jsonify({"status": "success", "data": portrait_data})
    except Exception as e:
        print(f"âŒ CSVå¤„ç†å¤±è´¥ï¼š{str(e)}")
        print(f"CSVå®é™…åˆ—åï¼š{[col.strip().upper() for col in df.columns] if df is not None else 'æœªè¯»å–åˆ°æ•°æ®'}")
        return jsonify({"status": "success", "data": {"age_dist": [], "city_dist": [], "consume_feat": [], "interest_feat": []}})


@app.route('/predict_customer_group', methods=['POST'])
def predict():
    try:
        req = request.get_json() or {}
        print(f"ğŸ“¥ é¢„æµ‹è¯·æ±‚å‚æ•°ï¼š{req}")
        # 1. æ„å»ºæ¨¡å‹è¾“å…¥ç‰¹å¾ï¼ˆä¸¥æ ¼éµå¾ª MODEL_FEATURE_ORDER é¡ºåºï¼‰
        features = []
        for feat in MODEL_FEATURE_ORDER:
            # ä»è¯·æ±‚ä¸­æå–å‚æ•°ï¼Œé€‚é…å¤§å°å†™ï¼ˆå¦‚ageâ†’AGEï¼Œpri_package_feeâ†’PRI_PACKAGE_FEEï¼‰
            req_key = None
            for key in req.keys():
                if key.strip().upper() == feat.upper():
                    req_key = key
                    break
            # æå–å€¼å¹¶è½¬æ¢ä¸ºæ•°å€¼ï¼ˆæ— å‚æ•°åˆ™ç”¨é»˜è®¤å€¼ï¼‰
            default_vals = {'AGE': 23, 'INNET_DURA': 12, 'PRI_PACKAGE_FEE': 88, 'ACCT_BAL': 50,
                            'N3M_AVG_DIS_ARPU': 90, 'day_flux': 5, 'night_flux': 2, 'N3M_AVG_GAME_APP_USE_DAYS': 5}
            if req_key:
                try:
                    val = float(req[req_key])
                except (ValueError, TypeError):
                    val = default_vals[feat]
                    print(f"âš ï¸ è¯·æ±‚å‚æ•°{req_key}ä¸æ˜¯æ•°å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼{val}")
            else:
                val = default_vals[feat]
                print(f"âš ï¸ è¯·æ±‚ä¸­æ— {feat}å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼{val}")
            features.append(val)
        # 2. æ¨¡å‹é¢„æµ‹ï¼ˆä¼˜å…ˆçœŸå®æ¨¡å‹ï¼Œå¤±è´¥æ‰æ¨¡æ‹Ÿï¼‰
        if MODEL_LOADED:
            try:
                # æ ‡å‡†åŒ–ç‰¹å¾ + é¢„æµ‹
                scaled_features = scaler.transform([features])
                pred_code = model.predict(scaled_features)[0]
                # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼Œå¢å¼ºç½®ä¿¡åº¦å¯ä¿¡åº¦ï¼‰
                if hasattr(model, 'predict_proba'):
                    pred_proba = model.predict_proba(scaled_features)[0]
                    confidence = round(max(pred_proba), 3)
                else:
                    confidence = round(np.random.uniform(0.85, 0.98), 3)
                print(f"âœ… æ¨¡å‹é¢„æµ‹æˆåŠŸï¼šå®¢ç¾¤ç¼–ç {pred_code}â†’{CUSTOMER_GROUP_MAP[pred_code]}ï¼Œç½®ä¿¡åº¦{confidence}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹é¢„æµ‹å¤±è´¥ï¼š{str(e)[:100]}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                pred_code = np.random.choice(list(CUSTOMER_GROUP_MAP.keys()))
                confidence = round(np.random.uniform(0.85, 0.98), 3)
        else:
            print(f"âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
            pred_code = np.random.choice(list(CUSTOMER_GROUP_MAP.keys()))
            confidence = round(np.random.uniform(0.85, 0.98), 3)
        # 3. è¿”å›ç»“æœï¼ˆç¡®ä¿å®¢ç¾¤ç¼–ç ä¸ºæ•´æ•°ï¼Œé™„å¸¦è¾“å…¥ç‰¹å¾æ–¹ä¾¿è°ƒè¯•ï¼‰
        return jsonify({
            "status": "success",
            "data": {
                "pred_code": int(pred_code),
                "pred_group": CUSTOMER_GROUP_MAP[pred_code],
                "confidence": confidence,
                "group_desc": GROUP_DESC[pred_code],
                "operation_advice": OPERATION_ADVICE[pred_code],
                "input_features": dict(zip(MODEL_FEATURE_ORDER, features))  # è¿”å›è¾“å…¥ç‰¹å¾ï¼Œæ–¹ä¾¿è°ƒè¯•
            }
        })
    except Exception as e:
        print(f"âŒ é¢„æµ‹æ¥å£å¼‚å¸¸ï¼š{str(e)}")
        return jsonify({
            "status": "error",
            "message": f"é¢„æµ‹å¤±è´¥ï¼š{str(e)}",
            "data": None
        })


@app.route('/get_eval_report')
def eval_report():
    try:
        # è¯»å–CSV
        csv_path = FILE_PATHS["eval_data"]
        df = None
        if os.path.exists(csv_path):
            try:
                df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)
            except:
                df = None
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šï¼ˆé€‚é…å¤§å†™åˆ—åï¼‰
        if df is not None and 'LABEL' in [col.upper() for col in df.columns] and 'PRED' in [col.upper() for col in
                                                                                            df.columns]:
            # æ‰¾åˆ°å®é™…åˆ—åï¼ˆå¤„ç†å¤§å°å†™ï¼‰
            label_col = next(col for col in df.columns if col.upper() == 'LABEL')
            pred_col = next(col for col in df.columns if col.upper() == 'PRED')
            y_true, y_pred = df[label_col], df[pred_col]
            accuracy = round(accuracy_score(y_true, y_pred), 2)
            recall = round(recall_score(y_true, y_pred, average='weighted'), 2)
            f1 = round(f1_score(y_true, y_pred, average='weighted'), 2)
            report = classification_report(y_true, y_pred, output_dict=True)
            group_metrics = []
            for i, name in CUSTOMER_GROUP_MAP.items():
                if str(i) in report:
                    metrics = report[str(i)]
                    group_metrics.append({
                        "group": name.split('ï¼ˆ')[0],
                        "precision": f"{round(metrics['precision'], 2)}",
                        "recall": f"{round(metrics['recall'], 2)}",
                        "f1": f"{round(metrics['f1-score'], 2)}",
                        "support": f"{int(metrics['support'])}"
                    })
            return jsonify({
                "status": "success",
                "data": {
                    "core_metrics": {"å‡†ç¡®ç‡(Accuracy)": f"{accuracy}", "å¬å›ç‡(Recall)": f"{recall}",
                                     "F1å€¼(F1-Score)": f"{f1}"},
                    "group_metrics": group_metrics,
                    "conclusion": f"æ¨¡å‹æ•´ä½“å‡†ç¡®ç‡{accuracy * 100}%ï¼Œé€‚åˆZä¸–ä»£å®¢ç¾¤è¯†åˆ«ã€‚"
                }
            })
        # æ— è¯„ä¼°åˆ—è¿”å›ç©ºæ•°æ®
        return jsonify({
            "status": "success",
            "data": {
                "core_metrics": {},
                "group_metrics": [],
                "conclusion": "CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°LABELå’ŒPREDåˆ—ï¼Œæ— æ³•ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"
            }
        })
    except Exception as e:
        print(f"âŒ è¯„ä¼°æŠ¥å‘Šå¤±è´¥ï¼š{str(e)}")
        return jsonify({
            "status": "error",
            "message": f"è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{str(e)}",
            "data": None
        })


# ========== å¯åŠ¨æœåŠ¡ ==========
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=8080)



